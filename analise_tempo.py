import pandas as pd
import os
from typing import Dict, List, Tuple, Optional
from datetime import timedelta
import glob

def format_timedelta(td):
    """Formata timedelta para HH:MM:SS"""
    if pd.isna(td):
        return None
    total_seconds = int(td.total_seconds())
    horas, resto = divmod(total_seconds, 3600)
    minutos, segundos = divmod(resto, 60)
    return f"{horas:02}:{minutos:02}:{segundos:02}"

def calcular_distancia_hodometro(df: pd.DataFrame) -> Dict:
    """Calcula a distÃ¢ncia percorrida baseada no hodÃ´metro"""
    resultado = {
        'primeiro_km': None,
        'ultimo_km': None,
        'distancia_percorrida': None,
        'data_primeiro': None,
        'data_ultimo': None,
        'total_registros_validos': 0
    }
    
    if 'HodÃ´metro Total' not in df.columns:
        print("âš ï¸ Coluna 'HodÃ´metro Total' nÃ£o encontrada!")
        return resultado
    
    df_work = df.copy()
    df_work['HodÃ´metro Total'] = pd.to_numeric(df_work['HodÃ´metro Total'], errors='coerce')
    
    registros_validos = df_work.dropna(subset=['HodÃ´metro Total'])
    registros_validos = registros_validos[registros_validos['HodÃ´metro Total'] > 0]
    
    if len(registros_validos) == 0:
        print("âš ï¸ Nenhum registro vÃ¡lido de hodÃ´metro encontrado!")
        return resultado
    
    registros_validos = registros_validos.sort_values('Data/Hora Evento')
    
    primeiro_registro = registros_validos.iloc[0]
    ultimo_registro = registros_validos.iloc[-1]
    
    resultado['primeiro_km'] = primeiro_registro['HodÃ´metro Total']
    resultado['ultimo_km'] = ultimo_registro['HodÃ´metro Total']
    resultado['data_primeiro'] = primeiro_registro['Data/Hora Evento']
    resultado['data_ultimo'] = ultimo_registro['Data/Hora Evento']
    resultado['total_registros_validos'] = len(registros_validos)
    
    if resultado['ultimo_km'] >= resultado['primeiro_km']:
        resultado['distancia_percorrida'] = resultado['ultimo_km'] - resultado['primeiro_km']
    else:
        resultado['distancia_percorrida'] = resultado['ultimo_km']
        print(f"âš ï¸ PossÃ­vel reset do hodÃ´metro detectado (Ãºltimo < primeiro)")
    
    return resultado

def contar_viagens(df: pd.DataFrame) -> Dict:
    """Conta viagens baseadas nos eventos IGNâ†’IGF"""
    resultado = {
        'total_viagens_completas': 0,
        'igf_sem_ign': 0,
        'ign_sem_igf': 0,
        'detalhes_viagens': [],
        'igf_orfaos': [],
        'ign_orfaos': []
    }
    
    df_ignicao = df[df['Tipo Mensagem'].isin(['IGN', 'IGF'])].copy()
    df_ignicao["Data/Hora Evento"] = pd.to_datetime(df_ignicao["Data/Hora Evento"], errors="coerce")
    df_ignicao = remover_mensagens_duplicadas(df_ignicao)
    df_ignicao = df_ignicao.sort_values('Data/Hora Evento').reset_index(drop=True)
    
    if len(df_ignicao) == 0:
        print("âš ï¸ Nenhum evento de igniÃ§Ã£o encontrado!")
        return resultado
    
    print(f"ğŸ” Analisando {len(df_ignicao)} eventos de igniÃ§Ã£o...")
    
    i = 0
    while i < len(df_ignicao):
        evento_atual = df_ignicao.iloc[i]
        
        if evento_atual['Tipo Mensagem'] == 'IGN':
            igf_encontrado = False
            j = i + 1
            
            while j < len(df_ignicao):
                proximo_evento = df_ignicao.iloc[j]
                
                if proximo_evento['Tipo Mensagem'] == 'IGF':
                    resultado['total_viagens_completas'] += 1
                    duracao = proximo_evento['Data/Hora Evento'] - evento_atual['Data/Hora Evento']
                    
                    resultado['detalhes_viagens'].append({
                        'viagem_numero': resultado['total_viagens_completas'],
                        'ignicao_ligada': evento_atual['Data/Hora Evento'],
                        'ignicao_desligada': proximo_evento['Data/Hora Evento'],
                        'duracao': duracao,
                        'duracao_formatada': format_timedelta(duracao),
                        'sequencia_ign': evento_atual['SequÃªncia'],
                        'sequencia_igf': proximo_evento['SequÃªncia']
                    })
                    
                    igf_encontrado = True
                    i = j + 1
                    break
                    
                elif proximo_evento['Tipo Mensagem'] == 'IGN':
                    break
                    
                j += 1
            
            if not igf_encontrado:
                resultado['ign_sem_igf'] += 1
                resultado['ign_orfaos'].append({
                    'data_hora': evento_atual['Data/Hora Evento'],
                    'sequencia': evento_atual['SequÃªncia'],
                    'status': 'IGN sem IGF correspondente'
                })
                i += 1
        
        elif evento_atual['Tipo Mensagem'] == 'IGF':
            resultado['igf_sem_ign'] += 1
            resultado['igf_orfaos'].append({
                'data_hora': evento_atual['Data/Hora Evento'],
                'sequencia': evento_atual['SequÃªncia'],
                'status': 'IGF sem IGN anterior'
            })
            i += 1
        
        else:
            i += 1
    
    return resultado

def adicionar_diffs(df: pd.DataFrame) -> pd.DataFrame:
    """Adiciona colunas de diferenÃ§a de tempo para posicionamento e modo econÃ´mico, alÃ©m da coluna LOG"""
    df_work = df.copy()
    
    df_work["Data/Hora InclusÃ£o"] = pd.to_datetime(df_work["Data/Hora InclusÃ£o"], errors="coerce")
    df_work["Data/Hora Evento"] = pd.to_datetime(df_work["Data/Hora Evento"], errors="coerce")
    df_work.sort_values(by=["Data/Hora InclusÃ£o", "SequÃªncia"], inplace=True, ignore_index=True)
    
    df_work["LOG"] = None
    df_work["Diff_Posicionamento"] = None
    df_work["Diff_ModoEco"] = None
    
    for i, row in df_work.iterrows():
        inclusao_time = row["Data/Hora InclusÃ£o"]
        evento_time = row["Data/Hora Evento"]
        
        if pd.notna(inclusao_time) and pd.notna(evento_time):
            diff_log = inclusao_time - evento_time
            df_work.at[i, "LOG"] = format_timedelta(diff_log)

    last_pos_time = None
    last_eco_time = None

    for i, row in df_work.iterrows():
        tipo = row["Tipo Mensagem"]
        evento_time = row["Data/Hora Evento"]

        if tipo == "IGN":
            last_pos_time = evento_time

        if tipo == "IGF":
            last_eco_time = evento_time

        if tipo == "Posicionamento por tempo em movimento":
            if last_pos_time is None:
                df_work.at[i, "Diff_Posicionamento"] = None
            else:
                diff = evento_time - last_pos_time
                df_work.at[i, "Diff_Posicionamento"] = format_timedelta(diff)
            last_pos_time = evento_time

        if tipo == "Modo econÃ´mico":
            if last_eco_time is None:
                df_work.at[i, "Diff_ModoEco"] = None
            else:
                diff = evento_time - last_eco_time
                df_work.at[i, "Diff_ModoEco"] = format_timedelta(diff)
            last_eco_time = evento_time

    cols = list(df_work.columns)
    
    for c in ["LOG", "Diff_Posicionamento", "Diff_ModoEco"]:
        if c in cols:
            cols.remove(c)
    
    cols.insert(2, "LOG")
    
    if "Tipo Mensagem" in cols:
        idx = cols.index("Tipo Mensagem")
        cols[idx+1:idx+1] = ["Diff_Posicionamento", "Diff_ModoEco"]
    
    df_work = df_work[cols]

    return df_work

def remover_mensagens_duplicadas(df: pd.DataFrame) -> pd.DataFrame:
    """Remove mensagens duplicadas baseadas em Tipo Mensagem, SequÃªncia e Data/Hora Evento"""
    df_clean = df.copy()
    
    duplicatas = df_clean.duplicated(subset=['Tipo Mensagem', 'SequÃªncia', 'Data/Hora Evento'], keep='first')
    total_duplicatas = duplicatas.sum()
    
    if total_duplicatas > 0:
        print(f"ğŸ§¹ Removendo {total_duplicatas} mensagens duplicadas...")
    
    df_clean = df_clean.drop_duplicates(subset=['Tipo Mensagem', 'SequÃªncia', 'Data/Hora Evento'], keep='first')
    
    return df_clean

def contar_reboots(df: pd.DataFrame) -> Tuple[int, List[Dict]]:
    """Conta quantas vezes houve reboot (sequÃªncia zerada)"""
    reboots = []
    reboot_count = 0
    
    df_sorted = df.sort_values(['Data/Hora InclusÃ£o', 'SequÃªncia']).reset_index(drop=True)
    
    for i in range(1, len(df_sorted)):
        seq_anterior = df_sorted.iloc[i-1]['SequÃªncia']
        seq_atual = df_sorted.iloc[i]['SequÃªncia']
        
        if seq_atual < seq_anterior and seq_atual <= 10:
            reboot_count += 1
            reboots.append({
                'Reboot_Numero': reboot_count,
                'Data_Hora': df_sorted.iloc[i]['Data/Hora InclusÃ£o'],
                'Sequencia_Anterior': seq_anterior,
                'Sequencia_Nova': seq_atual,
                'Tipo_Mensagem': df_sorted.iloc[i]['Tipo Mensagem']
            })
    
    return reboot_count, reboots

def analisar_intervalos_tempo(df: pd.DataFrame) -> Tuple[List[Dict], List[Dict]]:
    """Analisa intervalos de tempo para posicionamento e modo econÃ´mico"""
    anomalias_posicionamento = []
    anomalias_modo_eco = []
    
    tolerancia = timedelta(seconds=2)
    tempo_esperado_pos = timedelta(minutes=3)
    tempo_esperado_eco = timedelta(hours=1)
    
    for i, row in df.iterrows():
        if row['Tipo Mensagem'] == 'Posicionamento por tempo em movimento':
            diff_str = row['Diff_Posicionamento']
            if not pd.isna(diff_str) and isinstance(diff_str, str):
                try:
                    parts = diff_str.split(':')
                    diff_time = timedelta(hours=int(parts[0]), minutes=int(parts[1]), seconds=int(parts[2]))
                    
                    if not (tempo_esperado_pos - tolerancia <= diff_time <= tempo_esperado_pos + tolerancia):
                        anomalias_posicionamento.append({
                            'Sequencia': row['SequÃªncia'],
                            'Data_Hora': row['Data/Hora Evento'],
                            'Tempo_Esperado': '00:03:00',
                            'Tempo_Real': diff_str,
                            'Diferenca_Segundos': (diff_time - tempo_esperado_pos).total_seconds(),
                            'Status': 'Fora da tolerÃ¢ncia (Â±2s)'
                        })
                except (ValueError, IndexError, TypeError):
                    print(f"âš ï¸ Erro ao processar diff posicionamento: {diff_str}")
        
        if row['Tipo Mensagem'] == 'Modo econÃ´mico':
            diff_str = row['Diff_ModoEco']
            if not pd.isna(diff_str) and isinstance(diff_str, str):
                try:
                    parts = diff_str.split(':')
                    diff_time = timedelta(hours=int(parts[0]), minutes=int(parts[1]), seconds=int(parts[2]))
                    
                    if not (tempo_esperado_eco - tolerancia <= diff_time <= tempo_esperado_eco + tolerancia):
                        anomalias_modo_eco.append({
                            'Sequencia': row['SequÃªncia'],
                            'Data_Hora': row['Data/Hora Evento'],
                            'Tempo_Esperado': '01:00:00',
                            'Tempo_Real': diff_str,
                            'Diferenca_Segundos': (diff_time - tempo_esperado_eco).total_seconds(),
                            'Status': 'Fora da tolerÃ¢ncia (Â±2s)'
                        })
                except (ValueError, IndexError, TypeError):
                    print(f"âš ï¸ Erro ao processar diff modo econÃ´mico: {diff_str}")
    
    return anomalias_posicionamento, anomalias_modo_eco

def detectar_anomalias_ignicao(df: pd.DataFrame) -> List[Dict]:
    """Detecta anomalias de igniÃ§Ã£o (IGN/IGF consecutivos nÃ£o duplicados)"""
    anomalias = []
    
    df_ignicao = df[df['Tipo Mensagem'].isin(['IGN', 'IGF'])].copy()
    df_ignicao = remover_mensagens_duplicadas(df_ignicao)
    df_ignicao = df_ignicao.sort_values('Data/Hora Evento').reset_index(drop=True)
    
    for i in range(len(df_ignicao) - 1):
        atual = df_ignicao.iloc[i]
        proximo = df_ignicao.iloc[i + 1]
        
        if atual['Tipo Mensagem'] == proximo['Tipo Mensagem']:
            if atual['SequÃªncia'] != proximo['SequÃªncia']:
                anomalias.append({
                    'Tipo_Anomalia': f'{atual["Tipo Mensagem"]} Consecutivos',
                    'Sequencia_1': atual['SequÃªncia'],
                    'Sequencia_2': proximo['SequÃªncia'],
                    'Data_Hora_1': atual['Data/Hora Evento'],
                    'Data_Hora_2': proximo['Data/Hora Evento'],
                    'Diferenca_Tempo': proximo['Data/Hora Evento'] - atual['Data/Hora Evento'],
                    'Status': 'PossÃ­vel perda de evento intermediÃ¡rio'
                })
    
    return anomalias

def detectar_anomalias_velocidade(df: pd.DataFrame) -> List[Dict]:
    """Detecta anomalias de velocidade (excesso/retorno consecutivos nÃ£o duplicados)"""
    anomalias = []
    
    df_velocidade = df[df['Tipo Mensagem'].isin(['Excesso de velocidade', 'Retorno de velocidade'])].copy()
    df_velocidade = remover_mensagens_duplicadas(df_velocidade)
    df_velocidade = df_velocidade.sort_values('Data/Hora Evento').reset_index(drop=True)
    
    for i in range(len(df_velocidade) - 1):
        atual = df_velocidade.iloc[i]
        proximo = df_velocidade.iloc[i + 1]
        
        if atual['Tipo Mensagem'] == proximo['Tipo Mensagem']:
            if atual['SequÃªncia'] != proximo['SequÃªncia']:
                anomalias.append({
                    'Tipo_Anomalia': f'{atual["Tipo Mensagem"]} Consecutivos',
                    'Sequencia_1': atual['SequÃªncia'],
                    'Sequencia_2': proximo['SequÃªncia'],
                    'Data_Hora_1': atual['Data/Hora Evento'],
                    'Data_Hora_2': proximo['Data/Hora Evento'],
                    'Diferenca_Tempo': proximo['Data/Hora Evento'] - atual['Data/Hora Evento'],
                    'Status': 'PossÃ­vel perda de evento intermediÃ¡rio'
                })
    
    return anomalias

def detectar_mensagens_log_pos_igf(df: pd.DataFrame) -> List[Dict]:
    """
    Detecta grupos de mensagens em modo LOG (diff > 1min entre inclusÃ£o e evento)
    que ocorrem SOMENTE apÃ³s eventos IGF (igniÃ§Ã£o desligada).
    """
    anomalias_log = []
    
    df_sorted = df.sort_values('Data/Hora InclusÃ£o').reset_index(drop=True)
    limiar_log = timedelta(minutes=1)
    
    i = 0
    while i < len(df_sorted):
        row = df_sorted.iloc[i]
        
        if row['Tipo Mensagem'] == 'IGF':
            igf_data = row['Data/Hora Evento']
            igf_seq = row['SequÃªncia']
            
            mensagens_log = []
            j = i + 1
            
            while j < len(df_sorted):
                msg = df_sorted.iloc[j]
                
                inclusao_time = msg['Data/Hora InclusÃ£o']
                evento_time = msg['Data/Hora Evento']
                
                if pd.notna(inclusao_time) and pd.notna(evento_time):
                    diff_log = inclusao_time - evento_time
                    
                    if diff_log > limiar_log:
                        mensagens_log.append({
                            'sequencia': msg['SequÃªncia'],
                            'tipo_mensagem': msg['Tipo Mensagem'],
                            'data_hora_evento': evento_time,
                            'data_hora_inclusao': inclusao_time,
                            'diferenca_log': diff_log,
                            'diferenca_log_formatada': format_timedelta(diff_log)
                        })
                        j += 1
                    else:
                        break
                else:
                    j += 1
            
            if mensagens_log:
                total_mensagens = len(mensagens_log)
                primeira_msg = mensagens_log[0]
                ultima_msg = mensagens_log[-1]
                
                duracao_total = ultima_msg['data_hora_inclusao'] - primeira_msg['data_hora_evento']
                
                diffs_segundos = [msg['diferenca_log'].total_seconds() for msg in mensagens_log]
                diff_media = sum(diffs_segundos) / len(diffs_segundos)
                diff_max = max(diffs_segundos)
                diff_min = min(diffs_segundos)
                
                anomalias_log.append({
                    'IGF_Sequencia': igf_seq,
                    'IGF_Data_Hora': igf_data,
                    'Total_Mensagens_LOG': total_mensagens,
                    'Primeira_Mensagem_LOG': primeira_msg['data_hora_evento'],
                    'Ultima_Mensagem_LOG': ultima_msg['data_hora_evento'],
                    'Duracao_Total_Periodo': format_timedelta(duracao_total),
                    'Diff_LOG_Media_Segundos': f"{diff_media:.0f}",
                    'Diff_LOG_Minima_Segundos': f"{diff_min:.0f}",
                    'Diff_LOG_Maxima_Segundos': f"{diff_max:.0f}",
                    'Tipos_Mensagens': ', '.join(set([msg['tipo_mensagem'] for msg in mensagens_log])),
                    'Sequencias': f"{primeira_msg['sequencia']} a {ultima_msg['sequencia']}",
                    'Detalhes_Mensagens': mensagens_log
                })
                
                i = j
            else:
                i += 1
        else:
            i += 1
    
    return anomalias_log

def processar_arquivo(input_file: str, output_dir: str = "analises"):
    """Processa um Ãºnico arquivo e gera relatÃ³rio TXT e CSV processado"""
    
    print(f"\n{'='*100}")
    print(f"ğŸ” PROCESSANDO: {os.path.basename(input_file)}")
    print(f"{'='*100}")
    
    try:
        # Carregar dados
        df = pd.read_csv(input_file, sep=",")
        df.columns = df.columns.str.strip()
        print(f"âœ… Arquivo carregado: {len(df)} registros")
        
        # Calcular anÃ¡lises
        info_hodometro = calcular_distancia_hodometro(df)
        info_viagens = contar_viagens(df)
        df_com_diffs = adicionar_diffs(df)
        num_reboots, lista_reboots = contar_reboots(df_com_diffs)
        anomalias_pos, anomalias_eco = analisar_intervalos_tempo(df_com_diffs)
        anomalias_ignicao = detectar_anomalias_ignicao(df_com_diffs)
        anomalias_velocidade = detectar_anomalias_velocidade(df_com_diffs)
        anomalias_log_pos_igf = detectar_mensagens_log_pos_igf(df_com_diffs)

        # Extrair IMEI do nome do arquivo ou da primeira linha
        nome_arquivo = os.path.basename(input_file)
        imei = nome_arquivo.split('_')[0] if '_' in nome_arquivo else 'NÃ£o identificado'
        
        # Tentar pegar IMEI da coluna se existir
        if 'IMEI' in df.columns and len(df) > 0:
            imei_coluna = df['IMEI'].iloc[0]
            if pd.notna(imei_coluna):
                imei = str(imei_coluna)
        
        # Gerar relatÃ³rio TXT
        relatorio_txt = []
        relatorio_txt.append("="*100)
        relatorio_txt.append("ğŸ“‹ RELATÃ“RIO COMPLETO DE ANÃLISE")
        relatorio_txt.append("="*100)

        relatorio_txt.append(f"ğŸ“Š RESUMO GERAL:")
        relatorio_txt.append(f"   IMEI: {imei}")
        relatorio_txt.append(f"   ğŸ“ Total de Registros: {len(df)}")
        relatorio_txt.append(f"   ğŸ“… PerÃ­odo: {df_com_diffs['Data/Hora Evento'].min()} atÃ© {df_com_diffs['Data/Hora Evento'].max()}")
        
        relatorio_txt.append(f"\nğŸš— INFORMAÃ‡Ã•ES DO HODÃ”METRO:")
        if info_hodometro['distancia_percorrida'] is not None:
            relatorio_txt.append(f"   ğŸ Primeiro KM vÃ¡lido: {info_hodometro['primeiro_km']:.2f} km ({info_hodometro['data_primeiro']})")
            relatorio_txt.append(f"   ğŸ† Ãšltimo KM vÃ¡lido: {info_hodometro['ultimo_km']:.2f} km ({info_hodometro['data_ultimo']})")
            relatorio_txt.append(f"   ğŸ“ DistÃ¢ncia percorrida no perÃ­odo: {info_hodometro['distancia_percorrida']:.2f} km")
            relatorio_txt.append(f"   ğŸ“Š Total de registros vÃ¡lidos de hodÃ´metro: {info_hodometro['total_registros_validos']}")
        else:
            relatorio_txt.append(f"   âš ï¸ NÃ£o foi possÃ­vel calcular a distÃ¢ncia (dados insuficientes)")

        relatorio_txt.append(f"\nğŸ›£ï¸ INFORMAÃ‡Ã•ES DAS VIAGENS:")
        relatorio_txt.append(f"   âœ… Viagens completas (IGNâ†’IGF): {info_viagens['total_viagens_completas']}")
        relatorio_txt.append(f"   ğŸ”´ IGN sem IGF correspondente: {info_viagens['ign_sem_igf']}")
        relatorio_txt.append(f"   ğŸŸ  IGF sem IGN anterior: {info_viagens['igf_sem_ign']}")
        
        if info_viagens['detalhes_viagens']:
            relatorio_txt.append(f"   ğŸš— DETALHES DAS VIAGENS COMPLETAS:")
            for viagem in info_viagens['detalhes_viagens']:
                relatorio_txt.append(f"      {viagem['viagem_numero']:2d}. InÃ­cio: {viagem['ignicao_ligada']}")
                relatorio_txt.append(f"          Fim:    {viagem['ignicao_desligada']}")
                relatorio_txt.append(f"          DuraÃ§Ã£o: {viagem['duracao_formatada']} (Seq: {viagem['sequencia_ign']}â†’{viagem['sequencia_igf']})")
        
        if info_viagens['ign_orfaos']:
            relatorio_txt.append(f"   ğŸ”´ IGN Ã“RFÃƒOS (sem IGF correspondente):")
            for i, ign in enumerate(info_viagens['ign_orfaos'], 1):
                relatorio_txt.append(f"      {i:2d}. {ign['data_hora']} - Seq: {ign['sequencia']}")
        
        if info_viagens['igf_orfaos']:
            relatorio_txt.append(f"   ğŸŸ  IGF Ã“RFÃƒOS (sem IGN anterior):")
            for i, igf in enumerate(info_viagens['igf_orfaos'], 1):
                relatorio_txt.append(f"      {i:2d}. {igf['data_hora']} - Seq: {igf['sequencia']}")

        relatorio_txt.append(f"\nğŸ”„ REBOOTS DETECTADOS:")
        relatorio_txt.append(f"   ğŸ”¢ Total: {num_reboots}")
        if lista_reboots:
            for reboot in lista_reboots:
                relatorio_txt.append(f"   ğŸ“… {reboot['Data_Hora']} - Seq: {reboot['Sequencia_Anterior']} â†’ {reboot['Sequencia_Nova']}")
        
        relatorio_txt.append(f"\nâ° ANOMALIAS DE INTERVALOS:")
        relatorio_txt.append(f"   ğŸ¯ Posicionamento (esperado 3min Â±2s): {len(anomalias_pos)} anomalias")
        relatorio_txt.append(f"   ğŸ’¤ Modo EconÃ´mico (esperado 1h Â±2s): {len(anomalias_eco)} anomalias")

        if anomalias_pos:
            relatorio_txt.append(f"   ğŸ“ DETALHES COMPLETOS - Posicionamento:")
            for i, anom in enumerate(anomalias_pos, 1):
                relatorio_txt.append(f"      {i:3d}. Seq {anom['Sequencia']} ({anom['Data_Hora']}): {anom['Tempo_Real']} (diff: {anom['Diferenca_Segundos']:.0f}s)")

        if anomalias_eco:
            relatorio_txt.append(f"   ğŸ’¤ DETALHES COMPLETOS - Modo EconÃ´mico:")
            for i, anom in enumerate(anomalias_eco, 1):
                relatorio_txt.append(f"      {i:3d}. Seq {anom['Sequencia']} ({anom['Data_Hora']}): {anom['Tempo_Real']} (diff: {anom['Diferenca_Segundos']:.0f}s)")

        relatorio_txt.append(f"\nğŸ”¥ ANOMALIAS DE IGNIÃ‡ÃƒO:")
        relatorio_txt.append(f"   ğŸš¨ Total: {len(anomalias_ignicao)} anomalias")
        if anomalias_ignicao:
            relatorio_txt.append(f"   ğŸ”¥ DETALHES COMPLETOS - IgniÃ§Ã£o:")
            for i, anom in enumerate(anomalias_ignicao, 1):
                relatorio_txt.append(f"      {i:3d}. {anom['Tipo_Anomalia']}: Seq {anom['Sequencia_1']} â†’ {anom['Sequencia_2']}")
                relatorio_txt.append(f"           Data: {anom['Data_Hora_1']} â†’ {anom['Data_Hora_2']}")
                relatorio_txt.append(f"           Intervalo: {anom['Diferenca_Tempo']}")

        relatorio_txt.append(f"\nğŸƒ ANOMALIAS DE VELOCIDADE:")
        relatorio_txt.append(f"   ğŸš¨ Total: {len(anomalias_velocidade)} anomalias")
        if anomalias_velocidade:
            relatorio_txt.append(f"   ğŸƒ DETALHES COMPLETOS - Velocidade:")
            for i, anom in enumerate(anomalias_velocidade, 1):
                relatorio_txt.append(f"      {i:3d}. {anom['Tipo_Anomalia']}: Seq {anom['Sequencia_1']} â†’ {anom['Sequencia_2']}")
                relatorio_txt.append(f"           Data: {anom['Data_Hora_1']} â†’ {anom['Data_Hora_2']}")
                relatorio_txt.append(f"           Intervalo: {anom['Diferenca_Tempo']}")

        relatorio_txt.append(f"\nğŸ“ MENSAGENS EM LOG APÃ“S IGF:")
        relatorio_txt.append(f"   ğŸš¨ Total de ocorrÃªncias: {len(anomalias_log_pos_igf)}")
        if anomalias_log_pos_igf:
            relatorio_txt.append(f"   ğŸ“ DETALHES COMPLETOS - Mensagens em LOG apÃ³s IGF:")
            for i, anom in enumerate(anomalias_log_pos_igf, 1):
                relatorio_txt.append(f"      {i:3d}. IGF (Seq {anom['IGF_Sequencia']}) em {anom['IGF_Data_Hora']}")
                relatorio_txt.append(f"           â†’ {anom['Total_Mensagens_LOG']} mensagens em LOG detectadas")
                relatorio_txt.append(f"           â†’ SequÃªncias: {anom['Sequencias']}")
                relatorio_txt.append(f"           â†’ PerÃ­odo: {anom['Primeira_Mensagem_LOG']} atÃ© {anom['Ultima_Mensagem_LOG']}")

        relatorio_txt.append(f"\nğŸ‰ ANÃLISE CONCLUÃDA!")
        relatorio_txt.append("="*100)
        relatorio_txt.append("âœ… RELATÃ“RIO FINALIZADO COM SUCESSO!")
        relatorio_txt.append("="*100)

        # Gerar nome base do arquivo
        nome_base = os.path.splitext(os.path.basename(input_file))[0]
        
        # Criar diretÃ³rio de saÃ­da
        os.makedirs(output_dir, exist_ok=True)
        
        # Salvar relatÃ³rio TXT
        txt_output = os.path.join(output_dir, f"analise_{nome_base}.txt")
        with open(txt_output, "w", encoding="utf-8") as f:
            f.write("\n".join(relatorio_txt))
        print(f"ğŸ’¾ RelatÃ³rio TXT salvo: {txt_output}")
        
        # Salvar CSV processado
        csv_output = os.path.join(output_dir, f"analise_{nome_base}.csv")
        df_com_diffs.to_csv(csv_output, sep=",", index=False)
        print(f"ğŸ’¾ CSV processado salvo: {csv_output}")
        
        print(f"âœ… Processamento concluÃ­do com sucesso!\n")
        return True
        
    except Exception as e:
        print(f"âŒ Erro ao processar arquivo: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def processar_pasta(pasta_entrada: str, pasta_saida: str = "analises"):
    """
    Processa todos os arquivos CSV de uma pasta.
    
    Args:
        pasta_entrada: Caminho da pasta com os arquivos CSV
        pasta_saida: Caminho da pasta onde serÃ£o salvos os resultados
    """
    
    print("\n" + "="*100)
    print("ğŸš€ INICIANDO PROCESSAMENTO EM LOTE")
    print("="*100)
    
    # Verificar se a pasta existe
    if not os.path.exists(pasta_entrada):
        print(f"âŒ Pasta nÃ£o encontrada: {pasta_entrada}")
        return
    
    # Buscar todos os arquivos CSV na pasta
    arquivos_csv = glob.glob(os.path.join(pasta_entrada, "*.csv"))
    
    if not arquivos_csv:
        print(f"âŒ Nenhum arquivo CSV encontrado na pasta: {pasta_entrada}")
        return
    
    print(f"ğŸ“‚ Pasta de entrada: {pasta_entrada}")
    print(f"ğŸ“ Pasta de saÃ­da: {pasta_saida}")
    print(f"ğŸ“Š Total de arquivos encontrados: {len(arquivos_csv)}")
    print("="*100)
    
    # Processar cada arquivo
    sucessos = 0
    falhas = 0
    
    for i, arquivo in enumerate(arquivos_csv, 1):
        print(f"\n[{i}/{len(arquivos_csv)}] Processando: {os.path.basename(arquivo)}")
        
        if processar_arquivo(arquivo, pasta_saida):
            sucessos += 1
        else:
            falhas += 1
    
    # Resumo final
    print("\n" + "="*100)
    print("ğŸ“Š RESUMO DO PROCESSAMENTO")
    print("="*100)
    print(f"âœ… Arquivos processados com sucesso: {sucessos}")
    print(f"âŒ Arquivos com erro: {falhas}")
    print(f"ğŸ“ Resultados salvos em: {pasta_saida}/")
    print("="*100)
    print("ğŸ‰ PROCESSAMENTO EM LOTE CONCLUÃDO!")
    print("="*100)


if __name__ == "__main__":
    # ConfiguraÃ§Ã£o: defina aqui a pasta com os arquivos CSV
    PASTA_ENTRADA = "Decoder_GT06/decoded"  # Altere para sua pasta
    PASTA_SAIDA = "Decoder_GT06/analises"  # Pasta onde serÃ£o salvos os relatÃ³rios
    
    # Executar processamento em lote
    processar_pasta(PASTA_ENTRADA, PASTA_SAIDA)